{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look into the dataset and we could notice that the special character _\"\\N\"_ is used instead of _NaN_ for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>img_url</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>production_year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_year</th>\n",
       "      <th>studio</th>\n",
       "      <th>img_embeddings</th>\n",
       "      <th>text_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2502</td>\n",
       "      <td>Letters to Juliet</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjg0OT...</td>\n",
       "      <td>Letters to Juliet: Directed by Gary Winick. Wi...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92937.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Adventure,Comedy,Drama</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Sum.</td>\n",
       "      <td>[0.25030804, 2.4058464, 1.0431569, 0.030648155...</td>\n",
       "      <td>[-0.6795498, 0.35658365, 0.9994932, -0.9793934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6238</td>\n",
       "      <td>Veil of Tears</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZjMxOD...</td>\n",
       "      <td>Veil of Tears: Directed by William Gereghty. W...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>WF</td>\n",
       "      <td>[0.51250213, 2.8152602, 0.46308166, 0.29031387...</td>\n",
       "      <td>[-0.6202415, 0.31657028, 0.9992422, -0.9703722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>International Velvet</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BOGVkYj...</td>\n",
       "      <td>International Velvet: Directed by Bryan Forbes...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Drama,Family,Sport</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>MGM</td>\n",
       "      <td>[0.18073043, 0.24735461, 0.63652813, 0.2496522...</td>\n",
       "      <td>[-0.709996, 0.4233521, 0.99980927, -0.98892415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2675</td>\n",
       "      <td>8 Seconds</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYjY4Nz...</td>\n",
       "      <td>8 Seconds: Directed by John G. Avildsen. With ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4851.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Biography,Drama,Sport</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>NL</td>\n",
       "      <td>[0.025015268, 0.9105338, 0.3878257, 0.3421247,...</td>\n",
       "      <td>[-0.7416838, 0.38435012, 0.9998453, -0.9874693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3674</td>\n",
       "      <td>Penitentiary II</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNjQyZW...</td>\n",
       "      <td>Penitentiary II: Directed by Jamaa Fanaka. Wit...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1982</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Crime,Drama,Sport</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>MGM</td>\n",
       "      <td>[0.19079691, 1.9068279, 0.29114372, 0.19527505...</td>\n",
       "      <td>[-0.65501904, 0.3845747, 0.9996712, -0.9766391...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 title  \\\n",
       "0        2502     Letters to Juliet   \n",
       "1        6238         Veil of Tears   \n",
       "2        1800  International Velvet   \n",
       "3        2675             8 Seconds   \n",
       "4        3674       Penitentiary II   \n",
       "\n",
       "                                             img_url  \\\n",
       "0  https://m.media-amazon.com/images/M/MV5BMjg0OT...   \n",
       "1  https://m.media-amazon.com/images/M/MV5BZjMxOD...   \n",
       "2  https://m.media-amazon.com/images/M/MV5BOGVkYj...   \n",
       "3  https://m.media-amazon.com/images/M/MV5BYjY4Nz...   \n",
       "4  https://m.media-amazon.com/images/M/MV5BNjQyZW...   \n",
       "\n",
       "                                         description  ratings  n_votes  \\\n",
       "0  Letters to Juliet: Directed by Gary Winick. Wi...      6.5  92937.0   \n",
       "1  Veil of Tears: Directed by William Gereghty. W...      7.9     11.0   \n",
       "2  International Velvet: Directed by Bryan Forbes...      5.9   1345.0   \n",
       "3  8 Seconds: Directed by John G. Avildsen. With ...      6.6   4851.0   \n",
       "4  Penitentiary II: Directed by Jamaa Fanaka. Wit...      4.1    549.0   \n",
       "\n",
       "   is_adult  production_year  runtime                  genres  release_year  \\\n",
       "0         0             2010    105.0  Adventure,Comedy,Drama        2010.0   \n",
       "1         0             1996      NaN      Action,Crime,Drama        2014.0   \n",
       "2         0             1978    127.0      Drama,Family,Sport        1978.0   \n",
       "3         0             1994    105.0   Biography,Drama,Sport        1994.0   \n",
       "4         0             1982    108.0       Crime,Drama,Sport        1982.0   \n",
       "\n",
       "  studio                                     img_embeddings  \\\n",
       "0   Sum.  [0.25030804, 2.4058464, 1.0431569, 0.030648155...   \n",
       "1     WF  [0.51250213, 2.8152602, 0.46308166, 0.29031387...   \n",
       "2    MGM  [0.18073043, 0.24735461, 0.63652813, 0.2496522...   \n",
       "3     NL  [0.025015268, 0.9105338, 0.3878257, 0.3421247,...   \n",
       "4    MGM  [0.19079691, 1.9068279, 0.29114372, 0.19527505...   \n",
       "\n",
       "                                     text_embeddings  \n",
       "0  [-0.6795498, 0.35658365, 0.9994932, -0.9793934...  \n",
       "1  [-0.6202415, 0.31657028, 0.9992422, -0.9703722...  \n",
       "2  [-0.709996, 0.4233521, 0.99980927, -0.98892415...  \n",
       "3  [-0.7416838, 0.38435012, 0.9998453, -0.9874693...  \n",
       "4  [-0.65501904, 0.3845747, 0.9996712, -0.9766391...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X1: entry dataset (note: X2 is the testing dataset)\n",
    "# use row `Unamed: 0` as the row index\n",
    "X1 = pd.read_csv(\"datasets/X1.csv\", na_values=\"\\\\N\")\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1.loc[X1[\"title\"] == \"Clown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs dataset has dimension (3540, 14)\n",
    "\n",
    "One first thing we can notice is that our dataset use a special character \"\\\\N\" for empty values. We should modify them to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.158530e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.964834e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.164907e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.898197e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.697023e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       revenues\n",
       "0  7.158530e+07\n",
       "1  8.964834e+04\n",
       "2  3.164907e+07\n",
       "3  3.898197e+07\n",
       "4  9.697023e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y1: target dataset\n",
    "Y1 = pd.read_csv(\"datasets/Y1.csv\", header=None, names=[\"revenues\"])\n",
    "Y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target dataset has dimension (3540, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2: testing entry dataset\n",
    "X2 = pd.read_csv(\"datasets/X2.csv\", na_values=\"\\\\N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 dataset contains 3540 observations and 14 features\n",
      "X2 dataset (for prediction only) contains 1518 observations\n",
      "features: ['Unnamed: 0', 'title', 'img_url', 'description', 'ratings', 'n_votes', 'is_adult', 'production_year', 'runtime', 'genres', 'release_year', 'studio', 'img_embeddings', 'text_embeddings']\n",
      "target: ['revenues']\n"
     ]
    }
   ],
   "source": [
    "print(f\"X1 dataset contains {X1.shape[0]} observations and {X1.shape[1]} features\")\n",
    "print(f\"X2 dataset (for prediction only) contains {X2.shape[0]} observations\")\n",
    "\n",
    "print(f\"features: {list(X1.columns)}\")\n",
    "print(f\"target: {list(Y1.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "inputs (X1):     \n",
    "- `title`: title of the movie.    \n",
    "- `ratings`: rating on IMDB.    \n",
    "- `n_votes`: number of votes that are averaged for the given rating.    \n",
    "- `is_adult`: is the movie destined for a mature audience (0 or 1).    \n",
    "- `production_year`: the year the movie was produced.    \n",
    "- `release_year`: the year the movie was released.    \n",
    "- `runtime`: how long the movie lasts for (in minutes).    \n",
    "- `genres`: a list of maximum 3 genres that fits the movie.   \n",
    "- `studio`: the movie studio that produced the movie.        \n",
    "- `img.url`: the url of the poster of the movie.    \n",
    "- `img.embeddings`: vector of size 2048 representing the poster.    \n",
    "- `description`: synopsis of the movie.    \n",
    "- `text.embeddings`: vector of size 768 representing the synopsis.\n",
    "\n",
    "There is also an `\"Unnamed: 0\"` column that seems to be an **id for the movie**. We can remove it.\n",
    "\n",
    "target (Y1):     \n",
    "- `revenue`: the amount in dollars the movie made in the USA.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unecessary column `Unnamed: 0`\n",
    "X1.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature engineering and the sake of simplicity, we're gonna concatenate the inputs `X1` with the target `Y1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>img_url</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>production_year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_year</th>\n",
       "      <th>studio</th>\n",
       "      <th>img_embeddings</th>\n",
       "      <th>text_embeddings</th>\n",
       "      <th>revenues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Letters to Juliet</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjg0OT...</td>\n",
       "      <td>Letters to Juliet: Directed by Gary Winick. Wi...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92937.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Adventure,Comedy,Drama</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Sum.</td>\n",
       "      <td>[0.25030804, 2.4058464, 1.0431569, 0.030648155...</td>\n",
       "      <td>[-0.6795498, 0.35658365, 0.9994932, -0.9793934...</td>\n",
       "      <td>7.158530e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veil of Tears</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZjMxOD...</td>\n",
       "      <td>Veil of Tears: Directed by William Gereghty. W...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>WF</td>\n",
       "      <td>[0.51250213, 2.8152602, 0.46308166, 0.29031387...</td>\n",
       "      <td>[-0.6202415, 0.31657028, 0.9992422, -0.9703722...</td>\n",
       "      <td>8.964834e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International Velvet</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BOGVkYj...</td>\n",
       "      <td>International Velvet: Directed by Bryan Forbes...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Drama,Family,Sport</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>MGM</td>\n",
       "      <td>[0.18073043, 0.24735461, 0.63652813, 0.2496522...</td>\n",
       "      <td>[-0.709996, 0.4233521, 0.99980927, -0.98892415...</td>\n",
       "      <td>3.164907e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8 Seconds</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYjY4Nz...</td>\n",
       "      <td>8 Seconds: Directed by John G. Avildsen. With ...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4851.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Biography,Drama,Sport</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>NL</td>\n",
       "      <td>[0.025015268, 0.9105338, 0.3878257, 0.3421247,...</td>\n",
       "      <td>[-0.7416838, 0.38435012, 0.9998453, -0.9874693...</td>\n",
       "      <td>3.898197e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penitentiary II</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNjQyZW...</td>\n",
       "      <td>Penitentiary II: Directed by Jamaa Fanaka. Wit...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1982</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Crime,Drama,Sport</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>MGM</td>\n",
       "      <td>[0.19079691, 1.9068279, 0.29114372, 0.19527505...</td>\n",
       "      <td>[-0.65501904, 0.3845747, 0.9996712, -0.9766391...</td>\n",
       "      <td>9.697023e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                            img_url  \\\n",
       "0     Letters to Juliet  https://m.media-amazon.com/images/M/MV5BMjg0OT...   \n",
       "1         Veil of Tears  https://m.media-amazon.com/images/M/MV5BZjMxOD...   \n",
       "2  International Velvet  https://m.media-amazon.com/images/M/MV5BOGVkYj...   \n",
       "3             8 Seconds  https://m.media-amazon.com/images/M/MV5BYjY4Nz...   \n",
       "4       Penitentiary II  https://m.media-amazon.com/images/M/MV5BNjQyZW...   \n",
       "\n",
       "                                         description  ratings  n_votes  \\\n",
       "0  Letters to Juliet: Directed by Gary Winick. Wi...      6.5  92937.0   \n",
       "1  Veil of Tears: Directed by William Gereghty. W...      7.9     11.0   \n",
       "2  International Velvet: Directed by Bryan Forbes...      5.9   1345.0   \n",
       "3  8 Seconds: Directed by John G. Avildsen. With ...      6.6   4851.0   \n",
       "4  Penitentiary II: Directed by Jamaa Fanaka. Wit...      4.1    549.0   \n",
       "\n",
       "   is_adult  production_year  runtime                  genres  release_year  \\\n",
       "0         0             2010    105.0  Adventure,Comedy,Drama        2010.0   \n",
       "1         0             1996      NaN      Action,Crime,Drama        2014.0   \n",
       "2         0             1978    127.0      Drama,Family,Sport        1978.0   \n",
       "3         0             1994    105.0   Biography,Drama,Sport        1994.0   \n",
       "4         0             1982    108.0       Crime,Drama,Sport        1982.0   \n",
       "\n",
       "  studio                                     img_embeddings  \\\n",
       "0   Sum.  [0.25030804, 2.4058464, 1.0431569, 0.030648155...   \n",
       "1     WF  [0.51250213, 2.8152602, 0.46308166, 0.29031387...   \n",
       "2    MGM  [0.18073043, 0.24735461, 0.63652813, 0.2496522...   \n",
       "3     NL  [0.025015268, 0.9105338, 0.3878257, 0.3421247,...   \n",
       "4    MGM  [0.19079691, 1.9068279, 0.29114372, 0.19527505...   \n",
       "\n",
       "                                     text_embeddings      revenues  \n",
       "0  [-0.6795498, 0.35658365, 0.9994932, -0.9793934...  7.158530e+07  \n",
       "1  [-0.6202415, 0.31657028, 0.9992422, -0.9703722...  8.964834e+04  \n",
       "2  [-0.709996, 0.4233521, 0.99980927, -0.98892415...  3.164907e+07  \n",
       "3  [-0.7416838, 0.38435012, 0.9998453, -0.9874693...  3.898197e+07  \n",
       "4  [-0.65501904, 0.3845747, 0.9996712, -0.9766391...  9.697023e+06  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X1, Y1], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the different types of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of variables\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc641",
   "metadata": {},
   "source": [
    "- `n_votes` and `release_year` are of type **float** but we could have thought they would be of type **int**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4903d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.2937e+04, 1.1000e+01, 1.3450e+03, ..., 2.2860e+03, 4.1810e+03,\n",
       "       2.7379e+04])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"n_votes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a86ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2010., 2014., 1978., 1994., 1982., 2000., 1990., 2002., 1997.,\n",
       "       2009., 2001., 2003., 2007., 1992., 1998., 1995., 2008., 1983.,\n",
       "       2015., 1991., 2016., 2006., 1973., 2004., 2011., 1999., 1986.,\n",
       "       2005., 1996., 2013., 1993., 1989., 2012., 1987., 1988., 2017.,\n",
       "       1980., 1985., 1981., 1979., 1984., 1977., 2018., 1946., 1975.,\n",
       "       1966., 1971., 1974., 1941., 1957., 1970., 1976., 1972., 1959.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"release_year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sure we could convert `release_year` to type **int**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have any duplicate observations (we saw before that there could be duplicated movies with different `movie_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=df.columns.difference([\"revenues\"]))].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 432 duplicated observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is any empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values\n",
    "X2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for modelling :\n",
    "There are 264 missing values for `runtime` feature and 4 missing values for `genres` feature.\n",
    "\n",
    "Dataset for prediction :\n",
    "There are 106 missing values for `runtime` feature and 4 missing values for `genres` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing values\n",
    "((df.isna().sum() / df.shape[0]) * 100).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X2.isna().sum() / X2.shape[0]) * 100).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "sns.heatmap(df.isna(), cbar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the rows containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule of thumb**: _if values are missing at random and percentage of observations with these missing values are less than $5\\%$. We can drop them without risking of creating bias in our dataset._\n",
    "\n",
    "We have $0.3\\%$ of entries with missing values for `genres` features. These are random missing values (no reason for these to be missing, probably forgotten) so we can definitelty drop these entries without risk of creating bias in our dataset.\n",
    "However, for the `runtime` feature, we have ~ $7\\%$ of missing values. That's a little bit much for removing all these entries even though they also seem to be random missing values.\n",
    "\n",
    "We could try to impute by mean or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"runtime\"])\n",
    "\n",
    "print(df[\"runtime\"].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is missing randomly but the rows with these missing values are more than $5\\%$ of the dataset, we can use **mean** (in case feature is normally distributed) or **median** (otherwise) imputation. We can also consider **mode** imputation.\n",
    "\n",
    "However, keep in mind it affects data distribution (in particular the variance is reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"runtime mean: {}\".format(df[\"runtime\"].mean()))\n",
    "print(\"runtime median: {}\".format(df[\"runtime\"].median()))\n",
    "print(\"runtime mode: {}\".format(df[\"runtime\"].mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', '-', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'M', 'N', 'R', 'S',\n",
       "       'T', 'V', 'W', 'a', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n',\n",
       "       'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "df.dropna(subset=[\"genres\"], axis=0, inplace=True)\n",
    "\n",
    "genres_list = list(chain(*df[\"genres\"].str.split(\",\").tolist()))\n",
    "\n",
    "unique_genres = []\n",
    "genres_counter = {}\n",
    "\n",
    "# retrieve each genre\n",
    "for genre in genres_list:\n",
    "\tif genre in genres_counter:\n",
    "\t\tgenres_counter[genre] += 1\n",
    "\telse:\n",
    "\t\tgenres_counter[genre] = 1\n",
    "\n",
    "for genre, count in genres_counter.items():\n",
    "\tgenres_counter[genre] = np.round(count / len(genres_list), 3)\n",
    "\n",
    "genres_counter\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit_transform(df[\"genres\"])\n",
    "\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,30))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for col in df.select_dtypes(\"int\"):\n",
    "    plt.subplot(4,3,i)\n",
    "    sns.histplot(df[col])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be only _non-adult_ movies (to confirm later).\n",
    "\n",
    "Movies were mainly produced between **1990** and **2010**. We have a slightly left skewed distribution but it is more or less **normally distributed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_adult\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we **do not have any movies** for a _mature audience_. \n",
    "Therefore, we could drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,30))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for col in df.select_dtypes(\"float\"):\n",
    "    plt.subplot(4, 3, i)\n",
    "    sns.histplot(df[col])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ratings`, `runtime` and `release_year` features are more or less **normally distributed**.\n",
    "\n",
    "- `ratings` have a mean around **6.5**.\n",
    "\n",
    "- Most movies were released between **2005** and **2010**. \n",
    "\n",
    "- `n_votes` feature and `revenues` target are **heavily right skewed**. We will have to manage that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and outliers analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = df[\"n_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = df[\"revenues\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = np.log(df[\"n_votes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(df[\"n_votes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = np.log(df[\"revenues\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(df[\"revenues\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these two variables, 50% of the data are concentrated on a small range of values. But they contain a lot of outliers until pretty high values (that's why distribution is heavily right skewed).\n",
    "\n",
    "We see that we can perform a **log** transform on the 2 features to fix the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the range of the different numericals features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.select_dtypes(include=[\"int64\", \"float64\"]).max() - df.select_dtypes(include=[\"int64\", \"float64\"]).min()).round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we count the number of unique values for the 2 categorical features `genres` and `studio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genres\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`genre` feature contains list of maximum 3 most representative genres for each movies so there are many differents list of genres which does not mean there a as much different genres. We should preprocess them before then count how many different genres there are. \n",
    "However, we can expect there shouldn't be too many differents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"studio\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are $498$ different studios (**high-cardinality** problem), therefore, it will result in a lof of features if we One-Hot encode them. As a consequence, we would explose the dimensionnality of the datas and there would be more risk to overfit (curse of dimensionnality). Better to Label encode ? Let's check first the distribution of this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(df[\"studio\"]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some studio that only appear one time. We could definitely remove them and replace them by a category called `other`. Then One-Hot encode this feature.\n",
    "\n",
    "Or, we can also try \"Count Encoding\" that replaces each `studio` value with the number of times it appears in the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "841f872b124843c3cec9b84aa649cbdc5d28908a0e1b01e34eab5b6f0153b5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
