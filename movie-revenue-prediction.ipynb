{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0df188c-0709-4523-82e1-de9a4eee7dcb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b82f72d-dcb2-47e4-8600-8ee6d7af0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_predict, validation_curve, learning_curve\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from utils.preprocessing import preprocess_duplicated_and_missing, preprocess_irrelevant_features, one_hot_encode_genres_feature, count_encode_studio_feature, other_fixes, standardize\n",
    "from utils.process_embeddings import extract_embeddings_features, pca_on_embeddings\n",
    "from utils.feature_selection import select_features_correlation, select_features_MI, select_features_RFE\n",
    "from utils.model_selection import linreg, perform_grid_search, perform_random_search, evaluate_model, validate_model, compare_models\n",
    "from utils.plots import plot_correlation_matrix, plot_residuals, plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fc8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3fbf4",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec795d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "\tX1 = pd.read_csv(\"datasets/X1.csv\", na_values=\"\\\\N\")\n",
    "\tY1 = pd.read_csv(\"datasets/Y1.csv\", header=None, names=[\"revenues\"])\n",
    "\tX2 = pd.read_csv(\"datasets/X2.csv\", na_values=\"\\\\N\")\n",
    "\n",
    "\tX1.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\tdf = pd.concat([X1, Y1], axis = 1)\n",
    "\n",
    "\tprint(f\"X1 dataset contains {X1.shape[0]} observations and {X1.shape[1]} features\")\n",
    "\tprint(f\"X2 dataset (for prediction only) contains {X2.shape[0]} observations\")\n",
    "\n",
    "\treturn df, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d53fda",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2711b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dataset_name):\n",
    "\tprint(f\"PREPROCESSING {dataset_name}...\")\n",
    "\tprint(\"--------------------------\")\n",
    "\t# remove duplicated observations and preprocessing missing values\n",
    "\tdf = preprocess_duplicated_and_missing(df)\n",
    "\t# remove (obvious) irrelevant/redundant features\n",
    "\tdf = preprocess_irrelevant_features(df)\n",
    "\n",
    "\t# one-hot encode genres feature\n",
    "\tdf = one_hot_encode_genres_feature(df)\n",
    "\t#df = label_encode_studio_feature(df)\n",
    "\n",
    "\t# count encode studio feature\n",
    "\tdf = count_encode_studio_feature(df)\n",
    "\n",
    "\t# minor fixes\n",
    "\tdf = other_fixes(df)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf90033",
   "metadata": {},
   "source": [
    "## Feature extraction and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc1ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X, Y, run_pca=True):\n",
    "\tprint(\"FEATURE EXTRACTION...\")\n",
    "\tprint(\"--------------------------\")\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "\tprint(f\"training dataset dimension: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\tprint(f\"testing dataset dimension: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "\t# remove outliers only on train set\n",
    "\t# as test set should be representative of the reality\n",
    "\t#remove_outliers(X_train)\n",
    "\n",
    "\t# extract feature vectors\n",
    "\tX_train_img_embeddings = extract_embeddings_features(X_train[\"img_embeddings\"])\n",
    "\tX_test_img_embeddings = extract_embeddings_features(X_test[\"img_embeddings\"])\n",
    "\n",
    "\tX_train_text_embeddings = extract_embeddings_features(X_train[\"text_embeddings\"])\n",
    "\tX_test_text_embeddings = extract_embeddings_features(X_test[\"text_embeddings\"])\n",
    "\n",
    "\tX_train_img_df, X_test_img_df = pca_on_embeddings(X_train_img_embeddings, X_test_img_embeddings, X_train.index, X_test.index, prefix=\"img_feature\", total_variance_explained=0.8, run_pca=run_pca)\n",
    "\n",
    "\tX_train_text_df, X_test_text_df = pca_on_embeddings(X_train_text_embeddings, X_test_text_embeddings, X_train.index, X_test.index, prefix=\"text_feature\", total_variance_explained=0.8, run_pca=run_pca)\n",
    "\n",
    "\t# drop unnecessary features\n",
    "\tX_train.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\tX_test.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\n",
    "\t# standardize other features\n",
    "\tX_train, X_test, standard_scaler = standardize(X_train, X_test)\n",
    "\n",
    "\tX_train = pd.concat([X_train, X_train_img_df, X_train_text_df], axis=1)\n",
    "\tX_test = pd.concat([X_test, X_test_img_df, X_test_text_df], axis=1)\n",
    "\n",
    "\t# should also extract features for X2\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03ebfc-b137-4e30-a1a8-4621093f9a59",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c339f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 dataset contains 3540 observations and 13 features\n",
      "X2 dataset (for prediction only) contains 1518 observations\n",
      "PREPROCESSING modeling dataset\n",
      "--------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding\n",
      "[X] Count encoding\n",
      "[X] Minor fixes\n",
      "PREPROCESSING prediction dataset\n",
      "--------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding\n",
      "[X] Count encoding\n",
      "[X] Minor fixes\n",
      "FEATURE EXTRACTION\n",
      "--------------------------\n",
      "training dataset dimension: X_train: (2484, 34), y_train: (2484,)\n",
      "testing dataset dimension: X_test: (621, 34), y_test: (621,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf5479fe68a4bd39dfa010e3fbbdfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2258fec4b04e649b735d074c3d4079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b88122deed4a78b8da1d6711659468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5f7e1afcc04fc4b0052d76c82d0782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully reduced from 2048 features to 125 features keeping 80.0% of variance explained\n",
      "successfully reduced from 768 features to 3 features keeping 80.0% of variance explained\n",
      "FEATURE SELECTION (CORRELATION MATRIX)\n",
      "reduced from 160 features to 16 with features selection\n",
      "FEATURE SELECTION (MUTUAL INFORMATION)\n",
      "reduced from 160 features to 16 with features selection\n",
      "Correlation coefficient\n",
      "Linear Regression RMSE: 2.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathieu/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mathieu/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 213, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/mathieu/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 571, in _fit\n",
      "    raise TypeError(\n",
      "TypeError: n_neighbors does not take <class 'numpy.float64'> value, enter integer value\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "All estimators failed to fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zn/_2h7w2j547357vpm3_5pxrsr0000gn/T/ipykernel_7755/709152103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correlation coefficient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mutual Information\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab/movie-revenue-predictor/utils/model_selection.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(models, X_train, y_train, X_test, y_test, kf, scorer)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Linear Regression RMSE: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \t\tbest_estimator, best_params, best_score = perform_grid_search(\n",
      "\u001b[0;32m~/Lab/movie-revenue-predictor/utils/model_selection.py\u001b[0m in \u001b[0;36mperform_grid_search\u001b[0;34m(model, hyperparameters, X_train, y_train, X_test, y_test, kf, scorer)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# of out will be done in `_insert_error_scores`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                     \u001b[0m_insert_error_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_insert_error_scores\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuccessful_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All estimators failed to fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessful_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: All estimators failed to fit"
     ]
    }
   ],
   "source": [
    "df, X2 = read_datasets()\n",
    "\n",
    "# preprocessing \n",
    "df = preprocess(df, \"modeling dataset\")\n",
    "X2 = preprocess(X2, \"prediction dataset\")\n",
    "\n",
    "# spliting input and target\n",
    "X = df.drop(\"revenues\", axis=1)\n",
    "Y = df[\"revenues\"]\n",
    "\n",
    "# standardize, pca, train-test split\n",
    "X_train, X_test, y_train, y_test = extract_features(X, Y, run_pca=True)\n",
    "\n",
    "# feature selection\n",
    "X_train_corr, X_test_corr = select_features_correlation(X_train, y_train, X_test, percentile=10)\n",
    "X_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=10)\n",
    "#X_train_RFE, X_test_RFE = select_features_RFE(X_train, y_train, X_test)\n",
    "\n",
    "# model\n",
    "kf = KFold(n_splits=5)\n",
    "rmse = make_scorer(mean_squared_error, greater_is_better=True, squared=False)\n",
    "\n",
    "models = {\n",
    "\t\"KNN\": {\n",
    "\t\t\"instance\": KNeighborsRegressor(),\n",
    "\t\t\"hyperparameters\":  {\n",
    "\t\t\t\"n_neighbors\": np.arange(1, 55, 5),\n",
    "\t\t\t\"p\": [1, 2],\n",
    "\t\t\t\"weights\": [\"uniform\", \"distance\"]\n",
    "\t\t},\n",
    "\t\t\"validation_param\": \"n_neighbors\"\n",
    "\t},\n",
    "\t\"MLP\": {\n",
    "\t\t\"instance\": MLPRegressor(),\n",
    "\t\t\"hyperparameters\": {\n",
    "\t\t\t\"hidden_layer_sizes\": [(100,75,50), (75,50,25),(50,25,10)],\n",
    "\t\t\t\"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "\t\t\t\"alpha\": 10.0 ** -np.arange(1, 7), # https://scikit-learn.org/stable/modules/neural_networks_supervised.html,\n",
    "\t\t\t\"max_iter\": np.linspace(10, 100, 10)\n",
    "\t\t},\n",
    "\t\t\"validation_param\": \"hidden_layer_sizes\"\n",
    "\t},\n",
    "\t\"Random Forest\": {\n",
    "\t\t\"instance\": RandomForestRegressor(criterion=\"gini\", min_samples_split=30),\n",
    "\t\t\"hyperparameters\": {\n",
    "\t\t\t\"n_estimators\": np.linspace(100, 1000, 10),\n",
    "\t\t\t\"criterion\": [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "\t\t\t\"max_depth\": [3, 10, None] # none means unbounded max depth\n",
    "\t\t},\n",
    "\t\t\"validation_param\": \"n_estimators\"\n",
    "\t}\n",
    "}\n",
    "\n",
    "print(\"Correlation coefficient\")\n",
    "compare_models(models, X_train_corr, y_train, X_test_corr, y_test, kf, rmse)\n",
    "\n",
    "print(\"Mutual Information\")\n",
    "compare_models(models, X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "\n",
    "#print(\"Random Features Selection\")\n",
    "#compare_models(X_train_RFE, y_train, X_test_RFE, y_test, kf, scorer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb9791-4327-4477-b427-a151438c80ad",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We're gonna make prediction about the revenue of movies present in `X2.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "841f872b124843c3cec9b84aa649cbdc5d28908a0e1b01e34eab5b6f0153b5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
