{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0df188c-0709-4523-82e1-de9a4eee7dcb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b82f72d-dcb2-47e4-8600-8ee6d7af0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tikzplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_predict, validation_curve, learning_curve\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "\n",
    "from utils.preprocessing import preprocess_duplicated_and_missing, preprocess_irrelevant_features, one_hot_encode_genres_feature, one_hot_encode_studio_feature, remove_outliers, other_fixes, standardize\n",
    "from utils.feature_extraction import extract_embeddings_features, pca_on_embeddings\n",
    "from utils.feature_selection import get_mutual_information_matrix, normalize_mutual_information_matrix, select_features_MI_kbest, mrmr, select_features_RFECV\n",
    "from utils.model_selection import linreg, perform_grid_search, perform_random_search, ModelSelection\n",
    "from utils.plots import plot_correlation_matrix, plot_mutual_information_matrix, plot_mutual_information_with_target, plot_residuals, plot_predictions, validate_model_with_feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f65eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables for model selection\n",
    "N_SPLITS = 5\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=0)\n",
    "rmse = make_scorer(mean_squared_error, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fc8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3fbf4",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec795d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "\tX1 = pd.read_csv(\"datasets/X1.csv\", na_values=\"\\\\N\")\n",
    "\tY1 = pd.read_csv(\"datasets/Y1.csv\", header=None, names=[\"revenues\"])\n",
    "\tX2 = pd.read_csv(\"datasets/X2.csv\", na_values=\"\\\\N\")\n",
    "\n",
    "\tX1.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\tX2.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\tdf = pd.concat([X1, Y1], axis = 1)\n",
    "\n",
    "\tprint(f\"X1 dataset contains {X1.shape[0]} observations and {X1.shape[1]} features\")\n",
    "\tprint(f\"X2 dataset (for prediction only) contains {X2.shape[0]} observations\")\n",
    "\n",
    "\treturn df, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d53fda",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2711b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, train, X2, dataset_name):\n",
    "\tprint(\"-\" * 25)\n",
    "\tprint(f\"PREPROCESSING {dataset_name}...\")\n",
    "\tprint(\"-\" * 25)\n",
    "\t# remove duplicated observations and preprocessing missing values\n",
    "\tdf = preprocess_duplicated_and_missing(df, train)\n",
    "\tX2 = preprocess_duplicated_and_missing(X2, train)\n",
    "\n",
    "\t# remove (obvious) irrelevant/redundant features\n",
    "\tdf = preprocess_irrelevant_features(df)\n",
    "\tX2 = preprocess_irrelevant_features(X2)\n",
    "\n",
    "\t# fix high-cardinality + one-hot-encode studio feature\n",
    "\tdf, X2 = one_hot_encode_studio_feature(df, X2)\n",
    "\n",
    "\t# one-hot encode genres feature\n",
    "\tdf, X2 = one_hot_encode_genres_feature(df, X2)\n",
    "\n",
    "\t# minor fixes\n",
    "\tdf = other_fixes(df)\n",
    "\tX2 = other_fixes(X2)\n",
    "\treturn df, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf90033",
   "metadata": {},
   "source": [
    "## Feature extraction and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc1ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_and_split(X, Y):\n",
    "\tprint(\"-\" * 25)\n",
    "\tprint(\"REMOVING OUTLIERS AND TRAIN-TEST SPLIT...\")\n",
    "\tprint(\"-\" * 25)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "\tprint(f\"training dataset dimension: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\tprint(f\"testing dataset dimension: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "\t# remove outliers only on train set\n",
    "\t# as test set should be representative of the reality\n",
    "\tX_train, y_train = remove_outliers(X_train, y_train, [\"runtime\", \"production_year\", \"release_year\"])\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test\n",
    "\n",
    "def extract_features(X_train, y_train, X_test, y_test, X2, run_pca=True, non_linear=True):\n",
    "\tprint(\"-\" * 25)\n",
    "\tprint(\"FEATURE EXTRACTION...\")\n",
    "\tprint(\"-\" * 25)\n",
    "\n",
    "\t# extract feature vectors\n",
    "\tX_train_img_embeddings = extract_embeddings_features(X_train[\"img_embeddings\"])\n",
    "\tX_test_img_embeddings = extract_embeddings_features(X_test[\"img_embeddings\"])\n",
    "\n",
    "\tX_train_text_embeddings = extract_embeddings_features(X_train[\"text_embeddings\"])\n",
    "\tX_test_text_embeddings = extract_embeddings_features(X_test[\"text_embeddings\"])\n",
    "\n",
    "\t# should also extract features for X2\n",
    "\tX2_img_embeddings = extract_embeddings_features(X2[\"img_embeddings\"])\n",
    "\tX2_text_embeddings = extract_embeddings_features(X2[\"text_embeddings\"])\n",
    "\n",
    "\tX_train_img_df, X_test_img_df, X2_img_df = pca_on_embeddings(X_train_img_embeddings, X_test_img_embeddings, X2_img_embeddings, X_train.index, X_test.index, X2.index, prefix=\"img_feature\", total_variance_explained=0.6, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\tX_train_text_df, X_test_text_df, X2_text_df = pca_on_embeddings(X_train_text_embeddings, X_test_text_embeddings, X2_text_embeddings, X_train.index, X_test.index, X2.index, prefix=\"text_feature\", total_variance_explained=0.8, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\t# drop unnecessary features\n",
    "\tX_train.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\tX_test.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\tX2.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\n",
    "\t# standardize other features\n",
    "\tX_train, X_test, X2, standard_scaler = standardize(X_train, X_test, X2)\n",
    "\n",
    "\tX_train = pd.concat([X_train, X_train_img_df, X_train_text_df], axis=1)\n",
    "\tX_test = pd.concat([X_test, X_test_img_df, X_test_text_df], axis=1)\n",
    "\tX2 = pd.concat([X2, X2_img_df, X2_text_df], axis=1)\n",
    "\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03ebfc-b137-4e30-a1a8-4621093f9a59",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c339f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 dataset contains 3540 observations and 13 features\n",
      "X2 dataset (for prediction only) contains 1518 observations\n",
      "-------------------------\n",
      "PREPROCESSING modeling and prediction datasets...\n",
      "-------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding studio feature\n",
      "[X] One-Hot encoding genres feature\n",
      "[X] Minor fixes\n",
      "[X] Minor fixes\n"
     ]
    }
   ],
   "source": [
    "df, X2 = read_datasets()\n",
    "\n",
    "train_set = df\n",
    "\n",
    "# preprocessing \n",
    "df, X2 = preprocess(df, train_set, X2, \"modeling and prediction datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630abd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "REMOVING OUTLIERS AND TRAIN-TEST SPLIT...\n",
      "-------------------------\n",
      "training dataset dimension: X_train: (2484, 54), y_train: (2484,)\n",
      "testing dataset dimension: X_test: (621, 54), y_test: (621,)\n",
      "-------------------------\n",
      "FEATURE EXTRACTION...\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37efee72bd42bd9b36635ee9a51c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e995b820a4610b3a6d33f4c3e6907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc3e3303c734faf82c60eb6d5439a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d62324f80b447a9979b752f20948139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ee45006cf744a1b64407307b9f7af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/1425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc06959c0555416f875d601a90463f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/1425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully reduced from 2048 features to 56 features keeping 60.0% of variance explained\n",
      "successfully reduced from 768 features to 3 features keeping 80.0% of variance explained\n"
     ]
    }
   ],
   "source": [
    "# spliting input and target\n",
    "X = df.drop(\"revenues\", axis=1)\n",
    "Y = df[\"revenues\"]\n",
    "\n",
    "# remove outliers and train-test split\n",
    "X_train, y_train, X_test, y_test = remove_outliers_and_split(X, Y)\n",
    "\n",
    "# extract features + standardize (and pca)\n",
    "X_train, y_train, X_test, y_test, X2 = extract_features(X_train, y_train, X_test, y_test, X2, run_pca=True, non_linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f185571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_filtered, X_test_filtered = select_features_RFECV(X_train, y_train, X_test, kf, rmse)\n",
    "#X_train_filtered, X_test_filtered = select_features_MI_kbest(X_train, y_train, X_test, k=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c2ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores, columns = mrmr(X_train, y_train)\n",
    "\n",
    "# scores_df = pd.Series(scores, index=columns)\n",
    "# scores_df.plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEPT_FEATURES = ['n_votes', 'studio_other', 'release_year', 'production_year',\n",
    "#        'Adventure', 'runtime', 'studio_Uni.', 'studio_BV', 'studio_WB',\n",
    "#        'Action', 'studio_Par.', 'studio_SPC', 'studio_Fox',\n",
    "#        'text_feature2', 'img_feature43', 'text_feature0', 'studio_Col.',\n",
    "#        'studio_MGM', 'studio_Sony', 'studio_Orion', 'studio_Strand',\n",
    "#        'studio_Magn.', 'studio_IFC', 'studio_Mira.', 'studio_Eros',\n",
    "#        'Animation', 'studio_Reg.', 'studio_Gold.', 'studio_NL', 'Comedy',\n",
    "#        'Mystery', 'Horror', 'Fantasy', 'Drama', 'studio_FoxS']\n",
    "\n",
    "# OTHER_KEPT_FEATURES = ['n_votes', 'studio_other', 'release_year', 'Adventure', 'runtime',\n",
    "#        'studio_WB', 'studio_Uni.', 'Action', 'studio_BV', 'studio_Par.',\n",
    "#        'studio_SPC', 'img_feature0', 'studio_Fox', 'studio_Sony',\n",
    "#        'studio_Col.', 'studio_MGM', 'studio_Magn.', 'studio_Strand',\n",
    "#        'studio_Orion', 'studio_Mira.', 'Comedy', 'studio_IFC', 'Family']\n",
    "\n",
    "# X_train_filtered = X_train[columns[scores > 0.001]]\n",
    "# X_test_filtered = X_test[columns[scores > 0.001]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRETE_FEATURES = [\"ratings\", \"production_year\", \"release_year\"]\n",
    "# STUDIOS_FEATURES = X_train.columns[X_train.columns.str.startswith('studio')].tolist()\n",
    "# GENRES_FEATURES = X_train.coumns[X_train.columns.str.startswith(\"genre\")].tolist()\n",
    "\n",
    "# DISCRETE_FEATURES = np.concatenate(DISCRETE_FEATURES, STUDIOS_FEATURES, GENRES_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a798fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mutual_information_with_target(X_train, y_train)\n",
    "# tikzplotlib.save(\"report/figures/MI_with_target.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921645f9",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\" * 25)\n",
    "print(\"Linear Regression\")\n",
    "print(\"+\" * 25)\n",
    "\n",
    "val_score, rmse_score, r2 = linreg(X_train_filtered, y_train, X_test_filtered, y_test, kf, rmse)\n",
    "print(f\"val rmse: {round(val_score, 3)}\")\n",
    "print(f\"train rmse: {round(rmse_score, 3)}\")\n",
    "print(f\"train r2: {round(r2, 3)}\")\n",
    "\n",
    "val_score, rmse_score, r2 = linreg(X_train, y_train, X_test, y_test, kf, rmse)\n",
    "print(f\"val rmse: {round(val_score, 3)}\")\n",
    "print(f\"train rmse: {round(rmse_score, 3)}\")\n",
    "print(f\"train r2: {round(r2, 3)}\")\n",
    "\n",
    "# percentiles_candidates = [40, 45, 50, 55, 60]\n",
    "# val_scores = []\n",
    "# rmse_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# # test different percentage of features to keep (MI)\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "# \tval_score, rmse_score = linreg(X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "# \tval_scores.append(np.round(lr_score, 3))\n",
    "# \trmse_scores.append(np.round(rmse_score, 3))\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores (RMSE)\": val_scores,\n",
    "# \t\"test scores (RMSE)\": rmse_scores\n",
    "# })\n",
    "\n",
    "# plt.plot(percentiles_candidates, scores, color=\"blue\", marker=\"o\")\n",
    "# plt.title(\"Linear Regression: RMSE for different percentages of feature kept (MI)\")\n",
    "# plt.xlabel(\"percentage of features kepts\")\n",
    "# plt.ylabel(\"score (RMSE)\")\n",
    "\n",
    "# compare with RFE\n",
    "#X_train_RFE, X_test_RFE = select_features_RFE(X_train, y_train, X_test)\n",
    "#lr_score = linreg(X_train_RFE, y_train, X_test_RFE, y_test, kf, rmse)\n",
    "\n",
    "#print(\"[RFE] Linear Regression RMSE: {:.3f}\".format(lr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844385c0",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\" * 25)\n",
    "print(\"K-Nearset Neighbors\")\n",
    "print(\"+\" * 25)\n",
    "\n",
    "KNN_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=KNeighborsRegressor(), func=np.log, inverse_func=np.exp))\n",
    "])\n",
    "\n",
    "KNN = {\n",
    "\t\"instance\": KNN_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__n_neighbors\": np.linspace(1, 50, 10, dtype=int),\n",
    "\t\t\"model__regressor__p\": [1, 2],\n",
    "\t\t\"model__regressor__weights\": [\"uniform\", \"distance\"]\n",
    "\t},\n",
    "\t\"n_iter\": 100,\n",
    "\t\"validation_param\": \"model__regressor__n_neighbors\"\n",
    "}\n",
    "\n",
    "best_estimator, best_params, best_score = test_model(\n",
    "\tmodel=KNN, \n",
    "\tname=\"K-Nearest Neighbors\", \n",
    "\tX_train=X_train_filtered, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test_filtered, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")\n",
    "\n",
    "print(best_params)\n",
    "print(f\"train rmse: {round(best_score, 3)}\")\n",
    "\n",
    "# percentiles_candidates = [40, 50, 60]\n",
    "\n",
    "# estimators = []\n",
    "# scores = []\n",
    "\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "\n",
    "# \tbest_estimator, best_params, best_score = test_model(\n",
    "# \t\tmodel=KNN, \n",
    "# \t\tname=\"K-Nearest Neighbors\", \n",
    "# \t\tX_train=X_train_MI, \n",
    "# \t\ty_train=y_train, \n",
    "# \t\tX_test=X_test_MI, \n",
    "# \t\ty_test=y_test, \n",
    "# \t\tkf=kf, \n",
    "# \t\tscorer=rmse\n",
    "# \t)\n",
    "\n",
    "# \testimators.append(best_estimator)\n",
    "# \tscores.append(best_score)\n",
    "\n",
    "# validate_model_with_feature_selection(percentiles_candidates, estimators, \"K-Nearest Neighbors\", KNN[\"validation_param\"], KNN[\"hyperparameters\"][KNN[\"validation_param\"]], X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores\": scores\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b227d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(best_estimator, \"K-Nearest Neighbors\", KNN[\"validation_param\"], KNN[\"hyperparameters\"][KNN[\"validation_param\"]], X_train_filtered, y_train, X_test_filtered, y_test, kf, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fe568",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=MLPRegressor(), func=np.log1p, inverse_func=np.expm1))\n",
    "])\n",
    "\n",
    "MLP = {\n",
    "\t\"instance\": MLP_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__hidden_layer_sizes\": [(25,25,25),(25,25),(25,)],\n",
    "\t\t\"model__regressor__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "\t\t\"model__regressor__alpha\": 10.0 ** -np.arange(1, 7), # https://scikit-learn.org/stable/modules/neural_networks_supervised.html,\n",
    "\t\t\"model__regressor__max_iter\": [int(x) for x in np.linspace(10, 10000, 100)]\n",
    "\t},\n",
    "\t\"n_iter\": 10,\n",
    "\t\"validation_param\": \"model__regressor__hidden_layer_sizes\"\n",
    "}\n",
    "\n",
    "best_estimator, best_params, best_score = test_model(\n",
    "\tmodel=MLP, \n",
    "\tname=\"Multi-Layer Perceptron\", \n",
    "\tX_train=X_train_filtered, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test_filtered, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")\n",
    "\n",
    "print(best_params)\n",
    "print(f\"train rmse: {round(best_score, 3)}\")\n",
    "\n",
    "# percentiles_candidates = [40, 50, 60]\n",
    "\n",
    "# estimators = []\n",
    "# scores = []\n",
    "\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "\n",
    "# \tbest_estimator, best_params, best_score = test_model(\n",
    "# \t\tmodel=MLP, \n",
    "# \t\tname=\"Multi-Layer Perceptron\", \n",
    "# \t\tX_train=X_train_MI, \n",
    "# \t\ty_train=y_train, \n",
    "# \t\tX_test=X_test_MI, \n",
    "# \t\ty_test=y_test, \n",
    "# \t\tkf=kf, \n",
    "# \t\tscorer=rmse\n",
    "# \t)\n",
    "\n",
    "# \testimators.append(best_estimator)\n",
    "# \tscores.append(best_score)\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores\": scores\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08154bb5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a685d6d",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 0 \n",
    "oof_rmse = 0\n",
    "\n",
    "pred_rf_test = np.zeros(len(X2))\n",
    "\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_stra, X_val_stra = X_train.iloc[train_index, :], X_train.iloc[val_index, :]\n",
    "    y_train_stra, y_val_stra = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    print()\n",
    "    print(f\"Fold: {n_fold}\")\n",
    "    print()\n",
    "    \n",
    "    # setting up a basic random forest\n",
    "    random_forest_pipe = Pipeline([\n",
    "\t\t(\"model\", TransformedTargetRegressor(regressor=RandomForestRegressor(random_state=42, n_estimators=100), func=np.log1p, inverse_func=np.expm1))\n",
    "\t])\n",
    "    \n",
    "    # train the model on the stratified k-fold training set\n",
    "    random_forest_pipe.fit(X_train_stra, y_train_stra)\n",
    "    \n",
    "    # predict regression on the whole test set\n",
    "    pred = random_forest_pipe.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=pred))\n",
    "    print(f\"Fold {n_fold} -- test RMSE: {rmse}\")\n",
    "    \n",
    "    n_fold += 1\n",
    "    oof_rmse += rmse\n",
    "    \n",
    "    pred_rf_test += random_forest_pipe.predict(X2[X_train.columns]) / N_SPLITS\n",
    "  \n",
    "print(f\"Out-of-fold RMSE: {oof_rmse / N_SPLITS}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(12, 7))\n",
    "sns.set(rc={\"figure.figsize\": (9, 14)})\n",
    "\n",
    "sns.distplot(y_train, ax=ax[0])\n",
    "sns.distplot(pred_rf_test, ax=ax[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634c505",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b049053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "FEATURE SELECTION (MUTUAL INFORMATION)...\n",
      "-------------------------\n",
      "reduced from 111 features to 10 features\n",
      "-75834639.83237118\n",
      "Random Forest RMSE: 75834639.832\n",
      "-------------------------\n",
      "FEATURE SELECTION (MUTUAL INFORMATION)...\n",
      "-------------------------\n",
      "reduced from 111 features to 20 features\n",
      "-74690427.60908094\n",
      "Random Forest RMSE: 74690427.609\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features kepts [%]</th>\n",
       "      <th>val scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>7.583464e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>7.469043e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features kepts [%]    val scores\n",
       "0                  10  7.583464e+07\n",
       "1                  20  7.469043e+07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=RandomForestRegressor(random_state=42), func=np.log, inverse_func=np.exp))\n",
    "])\n",
    "\n",
    "rf = {\n",
    "\t\"instance\": random_forest_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__n_estimators\": [int(x) for x in np.linspace(35, 100, 10)],\n",
    "\t\t\"model__regressor__criterion\": [\"absolute_error\"], #[\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "\t\t\"model__regressor__max_features\": [\"auto\"], #[\"auto\", \"sqrt\"],\n",
    "\t\t\"model__regressor__max_depth\": [10, 12, None] #[3, 5, 7, 10, 12, None] # none means unbounded max depth\n",
    "\t},\n",
    "\t\"n_iter\": 10,\n",
    "\t\"validation_param\": \"model__regressor__max_depth\"\n",
    "}\n",
    "\n",
    "rf_bayes = {\n",
    "\t\"instance\": random_forest_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__n_estimators\": (35, 100),\n",
    "\t\t\"model__regressor__criterion\": [\"absolute_error\"], #[\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "\t\t\"model__regressor__max_depth\": (7, 12), #[3, 5, 7, 10, 12, None] # none means unbounded max depth\n",
    "\t\t\"model__regressor__min_samples_split\": (2, 20),\n",
    "    \t\"model__regressor__min_samples_leaf\": (1, 20)\n",
    "\t},\n",
    "\t\"n_iter\": 12,\n",
    "\t\"validation_param\": \"model__regressor__max_depth\"\n",
    "}\n",
    "\n",
    "# best_estimator, best_params, best_score = test_model(\n",
    "# \tmodel=rf, \n",
    "# \tname=\"Random Forest\", \n",
    "# \tX_train=X_train_filtered, \n",
    "# \ty_train=y_train, \n",
    "# \tX_test=X_test_filtered, \n",
    "# \ty_test=y_test, \n",
    "# \tkf=kf, \n",
    "# \tscorer=rmse\n",
    "# )\n",
    "\n",
    "# print(best_params)\n",
    "# print(f\"train rmse: {round(best_score, 3)}\")\n",
    "\n",
    "k_candidates = [10, 20]\n",
    "\n",
    "estimators = []\n",
    "scores = []\n",
    "\n",
    "for k in k_candidates:\n",
    "\tX_train_filtered, X_test_filtered = select_features_MI_kbest(X_train, y_train, X_test, k=k)\n",
    "\n",
    "\tms = ModelSelection(\n",
    "\t\tX_train=X_train_filtered,\n",
    "\t\ty_train=y_train,\n",
    "\t\tX_test=X_test_filtered,\n",
    "\t\ty_test=y_test,\n",
    "\t\tkf=kf,\n",
    "\t\tscorer=rmse\n",
    "\t)\n",
    "\n",
    "\tbest_estimator, best_params, best_score = ms.test_model(\n",
    "\t\tmodel=rf_bayes, \n",
    "\t\tname=\"Random Forest\"\n",
    "\t)\n",
    "\n",
    "\testimators.append(best_estimator)\n",
    "\tscores.append(round(best_score, 3))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "\t\"Features kepts [%]\": k_candidates,\n",
    "\t\"val scores\": scores\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b942840",
   "metadata": {},
   "source": [
    "#### Validation of the best model (overfitting, underfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7042bd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m best_number_of_faetures \u001b[39m=\u001b[39m k_candidates[best_idx]\n\u001b[1;32m      7\u001b[0m validation_param \u001b[39m=\u001b[39m rf[\u001b[39m\"\u001b[39m\u001b[39mvalidation_param\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m validate_model(\n\u001b[1;32m     10\u001b[0m \tmodel\u001b[39m=\u001b[39mbest_estimator, \n\u001b[1;32m     11\u001b[0m \tmodel_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRandom Forest\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     12\u001b[0m \tparam_name\u001b[39m=\u001b[39mvalidation_param, \n\u001b[1;32m     13\u001b[0m \tparam_range\u001b[39m=\u001b[39mrf[\u001b[39m\"\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m\"\u001b[39m][validation_param], \n\u001b[1;32m     14\u001b[0m \tX_train\u001b[39m=\u001b[39mX_train_filtered, \n\u001b[1;32m     15\u001b[0m \ty_train\u001b[39m=\u001b[39my_train, \n\u001b[1;32m     16\u001b[0m \tX_test\u001b[39m=\u001b[39mX_test_filtered, \n\u001b[1;32m     17\u001b[0m \ty_test\u001b[39m=\u001b[39my_test, \n\u001b[1;32m     18\u001b[0m \tkf\u001b[39m=\u001b[39mkf, \n\u001b[1;32m     19\u001b[0m \tscorer\u001b[39m=\u001b[39mrmse\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validate_model' is not defined"
     ]
    }
   ],
   "source": [
    "# plot validation curve of the best model\n",
    "best_idx = np.argmin(scores)\n",
    "\n",
    "best_estimator = estimators[best_idx]\n",
    "best_number_of_faetures = k_candidates[best_idx]\n",
    "\n",
    "validation_param = rf[\"validation_param\"]\n",
    "\n",
    "validate_model(\n",
    "\tmodel=best_estimator, \n",
    "\tmodel_name=\"Random Forest\", \n",
    "\tparam_name=validation_param, \n",
    "\tparam_range=rf[\"hyperparameters\"][validation_param], \n",
    "\tX_train=X_train_filtered, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test_filtered, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb9791-4327-4477-b427-a151438c80ad",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We're gonna make prediction about the revenue of movies present in `X2.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6743b992f85ac117cab049ed48a632619826b8873c950e8ced79a0748606aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
