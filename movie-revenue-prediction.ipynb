{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0df188c-0709-4523-82e1-de9a4eee7dcb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b82f72d-dcb2-47e4-8600-8ee6d7af0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_predict, validation_curve, learning_curve\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from utils.preprocessing import preprocess_duplicated_and_missing, preprocess_irrelevant_features, one_hot_encode_genres_feature, count_encode_studio_feature, other_fixes, standardize\n",
    "from utils.process_embeddings import extract_embeddings_features, pca_on_embeddings\n",
    "from utils.feature_selection import select_features_correlation, select_features_MI, select_features_RFE\n",
    "from utils.model_selection import linreg, perform_grid_search, perform_random_search, perform_bayesian_search, evaluate_model, validate_model, compare_models\n",
    "from utils.plots import plot_correlation_matrix, plot_residuals, plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fc8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3fbf4",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec795d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "\tX1 = pd.read_csv(\"datasets/X1.csv\", na_values=\"\\\\N\")\n",
    "\tY1 = pd.read_csv(\"datasets/Y1.csv\", header=None, names=[\"revenues\"])\n",
    "\tX2 = pd.read_csv(\"datasets/X2.csv\", na_values=\"\\\\N\")\n",
    "\n",
    "\tX1.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\tdf = pd.concat([X1, Y1], axis = 1)\n",
    "\n",
    "\tprint(f\"X1 dataset contains {X1.shape[0]} observations and {X1.shape[1]} features\")\n",
    "\tprint(f\"X2 dataset (for prediction only) contains {X2.shape[0]} observations\")\n",
    "\n",
    "\treturn df, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d53fda",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2711b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dataset_name):\n",
    "\tprint(f\"PREPROCESSING {dataset_name}...\")\n",
    "\tprint(\"--------------------------\")\n",
    "\t# remove duplicated observations and preprocessing missing values\n",
    "\tdf = preprocess_duplicated_and_missing(df)\n",
    "\t# remove (obvious) irrelevant/redundant features\n",
    "\tdf = preprocess_irrelevant_features(df)\n",
    "\n",
    "\t# one-hot encode genres feature\n",
    "\tdf = one_hot_encode_genres_feature(df)\n",
    "\t#df = label_encode_studio_feature(df)\n",
    "\n",
    "\t# count encode studio feature\n",
    "\tdf = count_encode_studio_feature(df)\n",
    "\n",
    "\t# minor fixes\n",
    "\tdf = other_fixes(df)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf90033",
   "metadata": {},
   "source": [
    "## Feature extraction and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc1ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X, Y, run_pca=True, non_linear=True):\n",
    "\tprint(\"FEATURE EXTRACTION...\")\n",
    "\tprint(\"--------------------------\")\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "\tprint(f\"training dataset dimension: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\tprint(f\"testing dataset dimension: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "\t# remove outliers only on train set\n",
    "\t# as test set should be representative of the reality\n",
    "\t#remove_outliers(X_train)\n",
    "\n",
    "\t# extract feature vectors\n",
    "\tX_train_img_embeddings = extract_embeddings_features(X_train[\"img_embeddings\"])\n",
    "\tX_test_img_embeddings = extract_embeddings_features(X_test[\"img_embeddings\"])\n",
    "\n",
    "\tX_train_text_embeddings = extract_embeddings_features(X_train[\"text_embeddings\"])\n",
    "\tX_test_text_embeddings = extract_embeddings_features(X_test[\"text_embeddings\"])\n",
    "\n",
    "\tX_train_img_df, X_test_img_df = pca_on_embeddings(X_train_img_embeddings, X_test_img_embeddings, X_train.index, X_test.index, prefix=\"img_feature\", total_variance_explained=0.8, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\tX_train_text_df, X_test_text_df = pca_on_embeddings(X_train_text_embeddings, X_test_text_embeddings, X_train.index, X_test.index, prefix=\"text_feature\", total_variance_explained=0.8, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\t# drop unnecessary features\n",
    "\tX_train.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\tX_test.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\n",
    "\t# standardize other features\n",
    "\tX_train, X_test, standard_scaler = standardize(X_train, X_test)\n",
    "\n",
    "\tX_train = pd.concat([X_train, X_train_img_df, X_train_text_df], axis=1)\n",
    "\tX_test = pd.concat([X_test, X_test_img_df, X_test_text_df], axis=1)\n",
    "\n",
    "\t# should also extract features for X2\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03ebfc-b137-4e30-a1a8-4621093f9a59",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c339f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 dataset contains 3540 observations and 13 features\n",
      "X2 dataset (for prediction only) contains 1518 observations\n",
      "PREPROCESSING modeling dataset...\n",
      "--------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding\n",
      "[X] Count encoding\n",
      "[X] Minor fixes\n",
      "PREPROCESSING prediction dataset...\n",
      "--------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding\n",
      "[X] Count encoding\n",
      "[X] Minor fixes\n",
      "FEATURE EXTRACTION...\n",
      "--------------------------\n",
      "training dataset dimension: X_train: (2484, 34), y_train: (2484,)\n",
      "testing dataset dimension: X_test: (621, 34), y_test: (621,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32925b14d614fd3885cdf73872dc355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6587d5fd49494b76ae7c905d25d80499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b284d416104f7d8fd5afce1aecfd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a811e705dc4dcb93284abb98524582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully reduced from 2048 features to 125 features keeping 80.0% of variance explained\n",
      "successfully reduced from 768 features to 3 features keeping 80.0% of variance explained\n",
      "FEATURE SELECTION (CORRELATION MATRIX)...\n",
      "reduced from 160 features to 32 features\n",
      "FEATURE SELECTION (MUTUAL INFORMATION)...\n",
      "reduced from 160 features to 32 features\n",
      "Mutual Information\n",
      "COMPARING MODELS...\n",
      "Linear Regression RMSE: 2.456\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'scorer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zn/_2h7w2j547357vpm3_5pxrsr0000gn/T/ipykernel_1351/2237004297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mutual Information\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mcompare_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_MI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_MI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#print(\"Random Features Selection\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab/movie-revenue-predictor/utils/model_selection.py\u001b[0m in \u001b[0;36mcompare_models\u001b[0;34m(models, X_train, y_train, X_test, y_test, kf, scorer)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \t\tbest_estimator, best_params, best_score = perform_bayesian_search(\n\u001b[0m\u001b[1;32m    113\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                         \u001b[0mhyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hyperparameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Lab/movie-revenue-predictor/utils/model_selection.py\u001b[0m in \u001b[0;36mperform_bayesian_search\u001b[0;34m(model, hyperparameters, n_iter, X_train, y_train, X_test, y_test, kf, scorer)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_bayesian_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mbayesion_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mbayesion_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'scorer'"
     ]
    }
   ],
   "source": [
    "df, X2 = read_datasets()\n",
    "\n",
    "# preprocessing \n",
    "df = preprocess(df, \"modeling dataset\")\n",
    "X2 = preprocess(X2, \"prediction dataset\")\n",
    "\n",
    "# spliting input and target\n",
    "X = df.drop(\"revenues\", axis=1)\n",
    "Y = df[\"revenues\"]\n",
    "\n",
    "# standardize, pca, train-test split\n",
    "X_train, X_test, y_train, y_test = extract_features(X, Y, run_pca=True, non_linear=False)\n",
    "\n",
    "# feature selection\n",
    "X_train_corr, X_test_corr = select_features_correlation(X_train, y_train, X_test, percentile=20)\n",
    "X_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=20)\n",
    "#X_train_RFE, X_test_RFE = select_features_RFE(X_train, y_train, X_test)\n",
    "\n",
    "# model\n",
    "kf = KFold(n_splits=5)\n",
    "rmse = make_scorer(mean_squared_error, greater_is_better=True, squared=False)\n",
    "\n",
    "models = {\n",
    "\t\"Random Forest\": {\n",
    "\t\t\"instance\": RandomForestRegressor(criterion=\"gini\", min_samples_split=30),\n",
    "\t\t\"hyperparameters\": {\n",
    "\t\t\t\"n_estimators\": np.linspace(100, 1000, 10),\n",
    "\t\t\t\"criterion\": [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "\t\t\t\"max_depth\": [3, 10, None] # none means unbounded max depth\n",
    "\t\t},\n",
    "\t\t\"n_iter\": 10,\n",
    "\t\t\"validation_param\": \"n_estimators\"\n",
    "\t},\n",
    "\t\"KNN\": {\n",
    "\t\t\"instance\": KNeighborsRegressor(),\n",
    "\t\t\"hyperparameters\":  {\n",
    "\t\t\t\"n_neighbors\": np.arange(1, 55, 5),\n",
    "\t\t\t\"p\": [1, 2],\n",
    "\t\t\t\"weights\": [\"uniform\", \"distance\"]\n",
    "\t\t},\n",
    "\t\t\"n_iter\": 5,\n",
    "\t\t\"validation_param\": \"n_neighbors\"\n",
    "\t},\n",
    "\t\"MLP\": {\n",
    "\t\t\"instance\": MLPRegressor(),\n",
    "\t\t\"hyperparameters\": {\n",
    "\t\t\t\"hidden_layer_sizes\": [(100,75,50),(75,50,25),(50,25,10),(25,25),(10,10),(10,)],\n",
    "\t\t\t\"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "\t\t\t\"alpha\": 10.0 ** -np.arange(1, 7), # https://scikit-learn.org/stable/modules/neural_networks_supervised.html,\n",
    "\t\t\t\"max_iter\": np.linspace(10, 100, 10)\n",
    "\t\t},\n",
    "\t\t\"n_iter\": 40,\n",
    "\t\t\"validation_param\": \"hidden_layer_sizes\"\n",
    "\t}\n",
    "}\n",
    "\n",
    "#print(\"Correlation coefficient\")\n",
    "#compare_models(models, X_train_corr, y_train, X_test_corr, y_test, kf, rmse)\n",
    "\n",
    "print(\"Mutual Information\")\n",
    "compare_models(models, X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "\n",
    "#print(\"Random Features Selection\")\n",
    "#compare_models(X_train_RFE, y_train, X_test_RFE, y_test, kf, scorer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb9791-4327-4477-b427-a151438c80ad",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We're gonna make prediction about the revenue of movies present in `X2.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "841f872b124843c3cec9b84aa649cbdc5d28908a0e1b01e34eab5b6f0153b5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
