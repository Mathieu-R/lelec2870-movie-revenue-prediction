{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0df188c-0709-4523-82e1-de9a4eee7dcb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b82f72d-dcb2-47e4-8600-8ee6d7af0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tikzplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_predict, validation_curve, learning_curve\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from utils.preprocessing import preprocess_duplicated_and_missing, preprocess_irrelevant_features, one_hot_encode_genres_feature, one_hot_encode_studio_feature, other_fixes, standardize\n",
    "from utils.feature_extraction import extract_embeddings_features, pca_on_embeddings\n",
    "from utils.feature_selection import get_mutual_information_matrix, normalize_mutual_information_matrix, select_features_MI, mrmr\n",
    "from utils.model_selection import linreg, perform_grid_search, perform_random_search, perform_halving_random_search, perform_bayesian_search, evaluate_model, validate_model, compare_models, test_model\n",
    "from utils.plots import plot_correlation_matrix, plot_mutual_information_matrix, plot_mutual_information_with_target, plot_residuals, plot_predictions, validate_model_with_feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f65eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables for model selection\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "rmse = make_scorer(mean_squared_error, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fc8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3fbf4",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec795d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "\tX1 = pd.read_csv(\"datasets/X1.csv\", na_values=\"\\\\N\")\n",
    "\tY1 = pd.read_csv(\"datasets/Y1.csv\", header=None, names=[\"revenues\"])\n",
    "\tX2 = pd.read_csv(\"datasets/X2.csv\", na_values=\"\\\\N\")\n",
    "\n",
    "\tX1.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\tdf = pd.concat([X1, Y1], axis = 1)\n",
    "\n",
    "\tprint(f\"X1 dataset contains {X1.shape[0]} observations and {X1.shape[1]} features\")\n",
    "\tprint(f\"X2 dataset (for prediction only) contains {X2.shape[0]} observations\")\n",
    "\n",
    "\treturn df, X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d53fda",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2711b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dataset_name):\n",
    "\tprint(\"-\" * 25)\n",
    "\tprint(f\"PREPROCESSING {dataset_name}...\")\n",
    "\tprint(\"-\" * 25)\n",
    "\t# remove duplicated observations and preprocessing missing values\n",
    "\tdf = preprocess_duplicated_and_missing(df)\n",
    "\t# remove (obvious) irrelevant/redundant features\n",
    "\tdf = preprocess_irrelevant_features(df)\n",
    "\n",
    "\t# fix high-cardinality + one-hot-encode studio feature\n",
    "\tdf = one_hot_encode_studio_feature(df)\n",
    "\n",
    "\t# one-hot encode genres feature\n",
    "\tdf = one_hot_encode_genres_feature(df)\n",
    "\n",
    "\t# minor fixes\n",
    "\tdf = other_fixes(df)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf90033",
   "metadata": {},
   "source": [
    "## Feature extraction and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc1ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X, Y, run_pca=True, non_linear=True):\n",
    "\tprint(\"-\" * 25)\n",
    "\tprint(\"FEATURE EXTRACTION...\")\n",
    "\tprint(\"-\" * 25)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "\tprint(f\"training dataset dimension: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\tprint(f\"testing dataset dimension: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "\t# remove outliers only on train set\n",
    "\t# as test set should be representative of the reality\n",
    "\t#remove_outliers(X_train)\n",
    "\n",
    "\t# extract feature vectors\n",
    "\tX_train_img_embeddings = extract_embeddings_features(X_train[\"img_embeddings\"])\n",
    "\tX_test_img_embeddings = extract_embeddings_features(X_test[\"img_embeddings\"])\n",
    "\n",
    "\tX_train_text_embeddings = extract_embeddings_features(X_train[\"text_embeddings\"])\n",
    "\tX_test_text_embeddings = extract_embeddings_features(X_test[\"text_embeddings\"])\n",
    "\n",
    "\tX_train_img_df, X_test_img_df = pca_on_embeddings(X_train_img_embeddings, X_test_img_embeddings, X_train.index, X_test.index, prefix=\"img_feature\", total_variance_explained=0.6, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\tX_train_text_df, X_test_text_df = pca_on_embeddings(X_train_text_embeddings, X_test_text_embeddings, X_train.index, X_test.index, prefix=\"text_feature\", total_variance_explained=0.8, run_pca=run_pca, non_linear=non_linear)\n",
    "\n",
    "\t# drop unnecessary features\n",
    "\tX_train.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\tX_test.drop([\"img_embeddings\", \"text_embeddings\"], axis=1, inplace=True)\n",
    "\n",
    "\t# standardize other features\n",
    "\tX_train, X_test, standard_scaler = standardize(X_train, X_test)\n",
    "\n",
    "\tX_train = pd.concat([X_train, X_train_img_df, X_train_text_df], axis=1)\n",
    "\tX_test = pd.concat([X_test, X_test_img_df, X_test_text_df], axis=1)\n",
    "\n",
    "\t# should also extract features for X2\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03ebfc-b137-4e30-a1a8-4621093f9a59",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c339f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 dataset contains 3540 observations and 13 features\n",
      "X2 dataset (for prediction only) contains 1518 observations\n",
      "-------------------------\n",
      "PREPROCESSING modeling dataset...\n",
      "-------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding studio feature\n",
      "[X] One-Hot encoding genres feature\n",
      "[X] Minor fixes\n",
      "-------------------------\n",
      "PREPROCESSING prediction dataset...\n",
      "-------------------------\n",
      "[X] Removing duplicated and missing values\n",
      "[X] Removing irrelevant features\n",
      "[X] One-Hot encoding studio feature\n",
      "[X] One-Hot encoding genres feature\n",
      "[X] Minor fixes\n",
      "-------------------------\n",
      "FEATURE EXTRACTION...\n",
      "-------------------------\n",
      "training dataset dimension: X_train: (2484, 54), y_train: (2484,)\n",
      "testing dataset dimension: X_test: (621, 54), y_test: (621,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6406f15c584adbbfa1f92cd69006fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098e950be5c94d588819f57790ba5dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09713aefe3540598b28a07c3e9377be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9541df5ad54e90aca6518eac3afa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extracting features:   0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully reduced from 2048 features to 56 features keeping 60.0% of variance explained\n",
      "successfully reduced from 768 features to 3 features keeping 80.0% of variance explained\n"
     ]
    }
   ],
   "source": [
    "df, X2 = read_datasets()\n",
    "\n",
    "# preprocessing \n",
    "df = preprocess(df, \"modeling dataset\")\n",
    "X2 = preprocess(X2, \"prediction dataset\")\n",
    "\n",
    "# spliting input and target\n",
    "X = df.drop(\"revenues\", axis=1)\n",
    "Y = df[\"revenues\"]\n",
    "\n",
    "# standardize, pca, train-test split\n",
    "X_train, X_test, y_train, y_test = extract_features(X, Y, run_pca=True, non_linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, columns = mrmr(X_train, y_train)\n",
    "\n",
    "scores_df = pd.Series(scores, index=columns)\n",
    "scores_df.plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5d06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns[scores > 0.001]\n",
    "\n",
    "KEPT_FEATURES = ['n_votes', 'studio_other', 'release_year', 'production_year',\n",
    "       'Adventure', 'runtime', 'studio_Uni.', 'studio_BV', 'studio_WB',\n",
    "       'Action', 'studio_Par.', 'studio_SPC', 'studio_Fox',\n",
    "       'text_feature2', 'img_feature43', 'text_feature0', 'studio_Col.',\n",
    "       'studio_MGM', 'studio_Sony', 'studio_Orion', 'studio_Strand',\n",
    "       'studio_Magn.', 'studio_IFC', 'studio_Mira.', 'studio_Eros',\n",
    "       'Animation', 'studio_Reg.', 'studio_Gold.', 'studio_NL', 'Comedy',\n",
    "       'Mystery', 'Horror', 'Fantasy', 'Drama', 'studio_FoxS']\n",
    "\n",
    "X_train = X_train[KEPT_FEATURES]\n",
    "X_test = X_test[KEPT_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCRETE_FEATURES = [\"ratings\", \"production_year\", \"release_year\"]\n",
    "STUDIOS_FEATURES = X_train.columns[X_train.columns.str.startswith('studio')].tolist()\n",
    "GENRES_FEATURES = X_train.coumns[X_train.columns.str.startswith(\"genre\")].tolist()\n",
    "\n",
    "DISCRETE_FEATURES = np.concatenate(DISCRETE_FEATURES, STUDIOS_FEATURES, GENRES_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a798fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mutual_information_with_target(X_train, y_train)\n",
    "tikzplotlib.save(\"report/figures/MI_with_target.tex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "921645f9",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f5e1d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++\n",
      "Linear Regression\n",
      "+++++++++++++++++++++++++\n",
      "69728273.214273\n",
      "78881846.08175164\n"
     ]
    }
   ],
   "source": [
    "print(\"+\" * 25)\n",
    "print(\"Linear Regression\")\n",
    "print(\"+\" * 25)\n",
    "\n",
    "val_score, rmse_score = linreg(X_train, y_train, X_test, y_test, kf, rmse)\n",
    "print(val_score)\n",
    "print(rmse_score)\n",
    "\n",
    "# percentiles_candidates = [40, 45, 50, 55, 60]\n",
    "# val_scores = []\n",
    "# rmse_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# # test different percentage of features to keep (MI)\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "# \tval_score, rmse_score = linreg(X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "# \tval_scores.append(np.round(lr_score, 3))\n",
    "# \trmse_scores.append(np.round(rmse_score, 3))\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores (RMSE)\": val_scores,\n",
    "# \t\"test scores (RMSE)\": rmse_scores\n",
    "# })\n",
    "\n",
    "# plt.plot(percentiles_candidates, scores, color=\"blue\", marker=\"o\")\n",
    "# plt.title(\"Linear Regression: RMSE for different percentages of feature kept (MI)\")\n",
    "# plt.xlabel(\"percentage of features kepts\")\n",
    "# plt.ylabel(\"score (RMSE)\")\n",
    "\n",
    "# compare with RFE\n",
    "#X_train_RFE, X_test_RFE = select_features_RFE(X_train, y_train, X_test)\n",
    "#lr_score = linreg(X_train_RFE, y_train, X_test_RFE, y_test, kf, rmse)\n",
    "\n",
    "#print(\"[RFE] Linear Regression RMSE: {:.3f}\".format(lr_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "844385c0",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab82d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++\n",
      "K-Nearset Neighbors\n",
      "+++++++++++++++++++++++++\n",
      "Pipeline(steps=[('model',\n",
      "                 TransformedTargetRegressor(func=<ufunc 'log'>,\n",
      "                                            inverse_func=<ufunc 'exp'>,\n",
      "                                            regressor=KNeighborsRegressor()))])\n",
      "{'model__regressor__weights': 'distance', 'model__regressor__p': 1, 'model__regressor__n_neighbors': 20}\n",
      "K-Nearest Neighbors RMSE: -8551450384677128.000\n",
      "Pipeline(steps=[('model',\n",
      "                 TransformedTargetRegressor(func=<ufunc 'log'>,\n",
      "                                            inverse_func=<ufunc 'exp'>,\n",
      "                                            regressor=KNeighborsRegressor(n_neighbors=20,\n",
      "                                                                          p=1,\n",
      "                                                                          weights='distance')))])\n",
      "{'model__regressor__weights': 'distance', 'model__regressor__p': 1, 'model__regressor__n_neighbors': 20}\n",
      "8551450384677128.0\n"
     ]
    }
   ],
   "source": [
    "print(\"+\" * 25)\n",
    "print(\"K-Nearset Neighbors\")\n",
    "print(\"+\" * 25)\n",
    "\n",
    "KNN_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=KNeighborsRegressor(), func=np.log, inverse_func=np.exp))\n",
    "])\n",
    "\n",
    "KNN = {\n",
    "\t\"instance\": KNN_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__n_neighbors\": np.linspace(20, 40, 10, dtype=int),\n",
    "\t\t\"model__regressor__p\": [1], #[1, 2],\n",
    "\t\t\"model__regressor__weights\": [\"uniform\", \"distance\"]\n",
    "\t},\n",
    "\t\"n_iter\": 10,\n",
    "\t\"validation_param\": \"model__regressor__n_neighbors\"\n",
    "}\n",
    "\n",
    "best_estimator, best_params, best_score = test_model(\n",
    "\tmodel=KNN, \n",
    "\tname=\"K-Nearest Neighbors\", \n",
    "\tX_train=X_train, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")\n",
    "\n",
    "print(best_estimator)\n",
    "print(best_params)\n",
    "print(-best_score)\n",
    "\n",
    "# percentiles_candidates = [40, 50, 60]\n",
    "\n",
    "# estimators = []\n",
    "# scores = []\n",
    "\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "\n",
    "# \tbest_estimator, best_params, best_score = test_model(\n",
    "# \t\tmodel=KNN, \n",
    "# \t\tname=\"K-Nearest Neighbors\", \n",
    "# \t\tX_train=X_train_MI, \n",
    "# \t\ty_train=y_train, \n",
    "# \t\tX_test=X_test_MI, \n",
    "# \t\ty_test=y_test, \n",
    "# \t\tkf=kf, \n",
    "# \t\tscorer=rmse\n",
    "# \t)\n",
    "\n",
    "# \testimators.append(best_estimator)\n",
    "# \tscores.append(best_score)\n",
    "\n",
    "# validate_model_with_feature_selection(percentiles_candidates, estimators, \"K-Nearest Neighbors\", KNN[\"validation_param\"], KNN[\"hyperparameters\"][KNN[\"validation_param\"]], X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores\": scores\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b227d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model_with_feature_selection(percentiles_candidates, estimators, \"K-Nearest Neighbors\", KNN[\"validation_param\"], KNN[\"hyperparameters\"][KNN[\"validation_param\"]], X_train_MI, y_train, X_test_MI, y_test, kf, rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "435fe568",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=MLPRegressor(), func=np.log, inverse_func=np.exp))\n",
    "])\n",
    "\n",
    "MLP = {\n",
    "\t\"instance\": MLP_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__hidden_layer_sizes\": [(25,25,25),(25,25),(25,)],\n",
    "\t\t\"model__regressor__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "\t\t\"model__regressor__alpha\": 10.0 ** -np.arange(1, 7), # https://scikit-learn.org/stable/modules/neural_networks_supervised.html,\n",
    "\t\t\"model__regressor__max_iter\": [int(x) for x in np.linspace(10, 10000, 100)]\n",
    "\t},\n",
    "\t\"n_iter\": 10,\n",
    "\t\"validation_param\": \"hidden_layer_sizes\"\n",
    "}\n",
    "\n",
    "best_estimator, best_params, best_score = test_model(\n",
    "\tmodel=MLP, \n",
    "\tname=\"Multi-Layer Perceptron\", \n",
    "\tX_train=X_train, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")\n",
    "\n",
    "print(best_estimator)\n",
    "print(best_params)\n",
    "print(best_score)\n",
    "\n",
    "# percentiles_candidates = [40, 50, 60]\n",
    "\n",
    "# estimators = []\n",
    "# scores = []\n",
    "\n",
    "# for percentile in percentiles_candidates:\n",
    "# \tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "\n",
    "# \tbest_estimator, best_params, best_score = test_model(\n",
    "# \t\tmodel=MLP, \n",
    "# \t\tname=\"Multi-Layer Perceptron\", \n",
    "# \t\tX_train=X_train_MI, \n",
    "# \t\ty_train=y_train, \n",
    "# \t\tX_test=X_test_MI, \n",
    "# \t\ty_test=y_test, \n",
    "# \t\tkf=kf, \n",
    "# \t\tscorer=rmse\n",
    "# \t)\n",
    "\n",
    "# \testimators.append(best_estimator)\n",
    "# \tscores.append(best_score)\n",
    "\n",
    "# pd.DataFrame({\n",
    "# \t\"Features keps [%]\": percentiles_candidates,\n",
    "# \t\"val scores\": scores\n",
    "# })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08154bb5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b049053",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([\n",
    "\t(\"model\", TransformedTargetRegressor(regressor=RandomForestRegressor(criterion=\"gini\", min_samples_split=30), func=np.log, inverse_func=np.exp))\n",
    "])\n",
    "\n",
    "random_forest = {\n",
    "\t\"instance\": random_forest_pipe,\n",
    "\t\"hyperparameters\": {\n",
    "\t\t\"model__regressor__n_estimators\": [int(x) for x in np.linspace(25, 40, 10)],\n",
    "\t\t\"model__regressor__criterion\": [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "\t\t\"model__regressor__max_features\": [\"auto\", \"sqrt\"],\n",
    "\t\t\"model__regressor__max_depth\": [3, 5, 7, 10, 12, None] # none means unbounded max depth\n",
    "\t},\n",
    "\t\"n_iter\": 10,\n",
    "\t\"validation_param\": \"max_depth\"\n",
    "},\n",
    "\n",
    "test_model(\n",
    "\tmodel=random_forest, \n",
    "\tname=\"Random Forest\", \n",
    "\tX_train=X_train_MI, \n",
    "\ty_train=y_train, \n",
    "\tX_test=X_test_MI, \n",
    "\ty_test=y_test, \n",
    "\tkf=kf, \n",
    "\tscorer=rmse\n",
    ")\n",
    "\n",
    "percentiles_candidates = np.arange(40, 65, 5)\n",
    "\n",
    "estimators = []\n",
    "scores = []\n",
    "\n",
    "for percentile in percentiles_candidates:\n",
    "\tX_train_MI, X_test_MI = select_features_MI(X_train, y_train, X_test, percentile=percentile)\n",
    "\n",
    "\tbest_estimator, best_params, best_score = test_model(\n",
    "\t\tmodel=random_forest, \n",
    "\t\tname=\"Random Forest\", \n",
    "\t\tX_train=X_train_MI, \n",
    "\t\ty_train=y_train, \n",
    "\t\tX_test=X_test_MI, \n",
    "\t\ty_test=y_test, \n",
    "\t\tkf=kf, \n",
    "\t\tscorer=rmse\n",
    "\t)\n",
    "\n",
    "\testimators.append(best_estimator)\n",
    "\tscores.append(best_score)\n",
    "\n",
    "#validate_model_with_feature_selection(percentiles, models, \"Random Forest\", random_forest[\"validation_param\"], random_forest[\"hyperparamaters\"][random_forest[\"validation_param\"]], X_train_MI, y_train, X_test_MI, y_test, kf, rmse)\n",
    "\n",
    "pd.DataFrame({\n",
    "\t\"Features keps [%]\": percentiles_candidates,\n",
    "\t\"val scores\": scores\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb9791-4327-4477-b427-a151438c80ad",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We're gonna make prediction about the revenue of movies present in `X2.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "841f872b124843c3cec9b84aa649cbdc5d28908a0e1b01e34eab5b6f0153b5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
